<section>
	<header class="main">
		<h1>Preliminary Program</h1>
	</header>

	<!-- dates -->
	<h2>Saturday, 13 October</h2>
	<div class="table-wrapper">
		<table>
			<tbody>
				<tr>
					<td style="width: 150px">8:30</td>
					<td>Registration opens</td>
				</tr>
				<tr>
					<td>9:00 - 9:15</td>
					<td>Opening</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>9:15 - 10:10</td>
					<td><span class="session-header">Session: Input and Output</span><br>
						<i>Robert J. Teather, Carleton University, Canada</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Pocket6: A 6DoF Controller Based On A Simple Smartphone App <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Teo Babic</u>, Harald Reiterer, Michael Haller</i></div>
							<div class="accordion-body">
								<br>
								We present Pocket6, a smartphone application for 6DoF user input. We present its implementation, performance study and demonstrate its use in diverse real-world scenarios.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Haptopus : Transferring the Touch Sense of the Hand to the Face Using Suction Mechanism Embedded in HMD <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Takayuki Kameoka</u>, Yuki Kon, Takuto Nakamura, Hiroyuki Kajimoto</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1059-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								We developed “Haptopus,” which embeds a tactile display in the HMD. Haptopus present high quality VR experience by transporting your fingertip sensation to your face using suction system.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>10:10 - 10:30</td>
					<td>Poster and Demo Fast Forward</td>
				</tr>
				<tr>
					<td>10:30 - 11:00</td>
					<td>Coffee break</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>11:00 - 12:30</td>
					<td><span class="session-header">Session: Sketching and Haptics</span><br>
						<i>Benjamin Weyers, RWTH Aachen University, Germany</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Performance Benefits of High-Fidelity Passive Haptic Feedback in Virtual Reality Training <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Anton Franzluebbers</u>, Kyle Johnsen</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1064-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								We describe a VR putting simulator uses a real golf club to move the virtual club. Our study finds performance and satisfaction benefits over ordinary controllers.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Physical Guides: An Analysis of 3D Sketching Performance on Physical Objects in Augmented Reality <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Philipp Wacker</u>, Adrian Wagner, Simon Voelker, Jan Borchers</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1053-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								How well can people trace specific lines on objects in AR? We compared tracing performance between physical and virtual objects as well as convex, concave, and visual guidance types.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Multiplanes: Assisted Freehand VR Sketching <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Mayra Donaji Barrera Machuca</u>, Paul Asente, Wolfgang Stuerzlinger, Jingwan Lu, Byungmoon Kim</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1034-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								Drawing in VR imposes high demands on users’ spatial cognition and motor skills. Multiplanes is a VR drawing system that let users sketch accurate 3D shapes in VR.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>12:30 - 13:30</td>
					<td>Lunch break (<i>on your own</i>)</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>13:30 - 15:00</td>
					<td><span class="session-header">Session: Presence and Collaboration</span><br>
						<i>Alexander Kulik, Bauhaus-Universität Weimar</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">IMRCE: A Unity Toolkit for Virtual Co-Presence <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Mohamad Hossein Salimian</u>, Stephen Brooks, Derek Reilly</i></div>
							<div class="accordion-body">
								<br>
								IMRCE is a lightweight, flexible, and robust Unity toolkit that allows designers and researchers to rapidly prototype mixed reality mixed presence (MR-MP) environments that connect physical spaces, virtual spaces and devices.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Over My Hand: Using a Personalized Hand in VR to Improve Object Size Estimation, Body Ownership, and Presence <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Sungchul Jung</u>, Gerd Bruder, Pamela J. Wisniewski, Christian Sandor, Dr. Charles E Hughes</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1018-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								In this paper, we investigate the impact of the personalized hand in VR in terms of virtual object size estimation, virtual bodyownership and spatial presence.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Injecting Nonverbal Mimicry with Hybrid Avatar-Agent Technologies: A naïve approach <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Daniel Roth</u>, David Mal, Christian Felix Purps, Peter Kullmann, Marc Erich Latoschik</i></div>
							<div class="accordion-body">
								<br>
								Future social interactions in VR will replicate user behavior with spatial and behavioral tracking. In our paper, we present an approach to modify these behavioral data by injecting nonverbal mimicry.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">A Look at the Effects of Handheld and Projected Augmented-reality on a Collaborative Task <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Eva Mackamul</u>, Augusto Esteves</i></div>
							<div class="accordion-body">
								<br>
								Our paper describes a study in which pairs of participants collaborate in handheld and project AR conditions. Their engagement, preference, task completion time, and number of actions is presented.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>15:00 - 15:30</td>
					<td>Coffee break and dedicated <a href="program#demos">Demo session</a></td>
				</tr>
				<tr style="background-color: #FFF3CD">
					<td>15:30 - 17:00</td>
					<td><span class="session-header">Keynote by <a href="keynote-olwal">Alex Olwal</a>:</span><br>
						<strong>Fusing Interfaces with Matter, Humans and Machines</strong>
					</td>
				</tr>
			</tbody>
		</table>
		<table>
			<tbody>
				<tr style="background-color: #D1ECF1">
					<td style="width: 150px">20:00 - 23:00</td>
					<td>SUI social event @ Computer Games Museum<br>
						<i>Transfer to CGM takes about 15 min with U-Bahn</i>
					</td>
				</tr>
			</tbody>
		</table>
	</div>


	<h2>Sunday, 14 October</h2>
	<div class="table-wrapper">
		<table>
			<tbody>
				<tr>
					<td style="width: 150px">8:30</td>
					<td>Registration opens</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>9:00 - 10:30</td>
					<td><span class="session-header">Session: Space and Learning</span><br>
						<i>Frank Steinicke, University of Hamburg, Germany</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Improving Spatial Orientation in Immersive Environments <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Joseph T Kotlarek</u>, I-Chen Lin, Kwan-Liu Ma</i></div>
							<div class="accordion-body">
								<br>
								Take a look at the best ways to help users explore scientific visualizations. We evaluate Landmarks, Teleportation and WIMs for navigating VR environments with fusion particle data.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Effects of VE Transition Techniques on Presence, Illusion of Virtual Body Ownership, Efficiency, and Naturalness <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Sebastian Oberdörfer</u>, Martin Fischbach, Marc Erich Latoschik</i></div>
							<div class="accordion-body">
								<br>
								This paper presents three realizations of transition techniques targeting a travel between individual VEs. The metaphors are compared in regard to their effect on presence, IVBO, efficiency, and naturalism.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Getting There and Beyond: Incidental Learning of Spatial Knowledge with Turn-by-Turn Directions and Location Updates in Navigation Interfaces <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Sanorita Dey</u>, Karrie Karahalios, Wai-Tat Fu</i></div>
							<div class="accordion-body">
								<br>
								Simple design elements such as interactive location update and interactive orientation update can help people learn spatial knowledge incidentally while using a navigation interface. Let's find out how it works.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>10:30 - 11:00</td>
					<td>Coffee break and dedicated <a href="program#posters">Poster session</a>
					</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>11:00 - 12:30</td>
					<td><span class="session-header">Session: Selection and Travel</span><br>
						<i>Wolfgang Stuerzlinger, Simon Fraser University, Canada</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Evaluating the Effects of Feedback Type on Older Adults’ Performance in Mid-Air Pointing and Target Selection <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Arthur Theil Cabreira</u>, Faustina Hwang</i></div>
							<div class="accordion-body">
								<br>
								In this work, we report the findings of a target acquisition experiment that investigated the effects of different 6 feedback conditions on how older adults performed point-and-select tasks in mid-air.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Evaluation of Cursor Offset on 3D Selection in VR <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i>Jialei Li, Isaac Cho, <u>Zachary Wartell</u></i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1096-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								Evaluation of four virtual cursor offset techniques on 3D object selection using Razer Hydra and Leap Motion in the Oculus Rift HMD.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Look to Go: An Empirical Evaluation of Eye-Based Travel in Virtual Reality <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i>YuanYuan Qian, <u>Robert J Teather</u></i></div>
							<div class="accordion-body">
								<br>
								We present two studies using the eye for locomotion in VR, using the eye tracker provided in the FOVE HMD.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>12:30 - 13:30</td>
					<td>Lunch (<i>on your own</i>)</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>13:30 - 15:00</td>
					<td><span class="session-header">Session: Robotics and Wearables</span><br>
						<i>Dimitar Valkov, University of Münster, Germany</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">RobotIST: Interactive Situated Tangible Robot Programming <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Yasaman S. Sefidgar</u>, Thomas Weng, Heather Harvey, Sarah Elliott, Maya Cakmak</i></div>
							<div class="accordion-body">
								<br>
								RobotIST enables robot programmers to program robotic manipulation of the physical environment in the physical space, leveraging tangible programming blocks as user input and providing projected feedback as system output.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Thumb-In-Motion: Evaluating Thumb to Ring Microgestures for Athletic Activity <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i>Roger Boldu, Alexandru Dancu, <u>Denys J.C. Matthies</u>, Pablo Gallego Cascón, Shanaka Ransiri, Suranga Nanayakkara</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1089-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								In this paper, we evaluate a one-handed thumb-to-ring gesture interface to quickly access information without interfering with physical activity, such as running.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Development of a Wearable Haptic Device that Presents the Haptic  Sensation Corresponding to Three Fingers on the Forearm <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Taha Moriyama</u>, Takuto Nakamura, Hiroyuki Kajimoto</i></div>
							<div class="accordion-body">
								<br>
								In this paper, as an attempt for objects in virtual reality environment, we show a device that presents haptics sensation of the fingertip on the forearm, not on the fingertip.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Step Detection for Rollator Users with Smartwatches <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Denys J.C. Matthies</u>, Marian Haescher, Suranga Nanayakkara, Gerald Bieber</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1023-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								We introduce an improved step-counting-algorithm for wrist-worn accelerometers. Our algorithm is capable of recognising steps when pulling/pushing objects, such as a rollator, which is a common assistive device for elderly people.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>15:00 - 15:30</td>
					<td>Coffee break</td>
				</tr>
				<tr style="background-color: #FFF3CD">
					<td>15:30 - 17:00</td>
					<td><span class="session-header">Closing Keynote by <a href="keynote-welch">Gregory Welch</a>:</span><br>
					<strong>The Rise of Allocentric Interfaces and the Collapse of the Virtuality Continuum</strong>
					</td>
				</tr>
				<tr>
					<td>17:00 - 17:30</td>
					<td>SUI 2018 Awards and Closing</td>
				</tr>
			</tbody>
		</table>
		<table>
			<tbody>
			<tr style="background-color: #D1ECF1">
					<td style="width: 150px">18:00 - 21:00</td>
					<td><a href="https://uist.acm.org/uist2018/program">UIST Reception and Demos at HPI</a><br>
						<i>(opened for SUI attendees)</i><br>
						<i>Transfer to HPI takes about 40 min with S-Bahn</i>
					</td>
				</tr>
			</tbody>
		</table>
	</div>

	<!--
	<h2>Monday, 15 October</h2>
	<div class="table-wrapper">
		<table>
			<tbody>
				<tr>
					<td style="width: 150px">10:00 - 11:00</td>
					<td>UIST Keynote by Jaime Teevan<br>
						<i>(opened for SUI attendees)</i>
					</td>
				</tr>
			</tbody>
		</table>
	</div>
	-->

</section>

<section id="posters">

	<h2>Posters</h2>
	<div class="table-wrapper">
		<table>
			<tbody>
			<tr>
				<td>
					<div><span class="session-header">An Exploration of Altered Muscle Mappings of Arm to Finger Control for 3D Selection</span></div>
					<div><i>Elliot Hunt, Amy Banic</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Haptic Interface Using Tendon Electrical Stimulation: Evaluation of the Effectiveness on Multimodal Presentation</span></div>
					<div><i>Akifumi Takahashi, Kenta Tanabe, Hiroyuki Kajimoto</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Flying a Broom in a Hybrid Reality Room: Eliciting Physical Interaction</span></div>
					<div><i>Nurit Kirshenbaum, Dylan Kobayashi, Ryan Theriot, Kari Noe, Jason Leigh</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Towards Unobtrusive Obstacle Detection and Notification for Virtual Reality Using Metaphors</span></div>
					<div><i>Peter Wozniak, Antonio Capobianco, Nicolas Javahiraly, Dan Curticapean</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Exploring the Potential and Challenges of VR Prototyping in Fashion Design</span></div>
					<div><i>Jamil L Joundi, Peter Conradie, Jelle Saldien, Lieven De Marez</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Doodle Daydream: An Interactive Display to Support Playful and Creative Interactions Between Co-workers</span></div>
					<div><i>Don Samitha Elvitigala, Samantha W.T. Chan, Noura Howell, Denys J.C. Matthies, Suranga Nanayakkara</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Classification of Beyond-Reality Interaction Techniques in Spatial Human-Computer Interaction</span></div>
					<div><i>Bastian Dewitz, Philipp Ladwig, Frank Steinicke, Christian Geiger</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">An Emotional Spatial Handwriting System</span></div>
					<div><i>Ziqian Chen, Marie-Luce Bourguet, Gentiane Venture</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Identification of Out-of-View Objects in Virtual Reality</span></div>
					<div><i>Uwe Gruenefeld, Rieke von Bargen, Wilko Heuten</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Multiple Pointing Method with Smartphone Gyro Sensor</span></div>
					<div><i>Koki Sato, Shigeo Kitamura, Mitsunori Matsushita</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Virtual Campus: Infrastructure and spatiality management tools based on 3D environments</span></div>
					<div><i>Tatiana Sánchez Botero, Alejandro Montes Muñoz</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Spaceline: A Way of Interaction in Cinematic Virtual Reality</span></div>
					<div><i>Sylvia Rothe, Harald Brunner, Daniel Buschek, Heinrich Hussmann</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Real-Time Recognition of Signboards with Mobile Device using Deep Learning for Information Identification Support System</span></div>
					<div><i>Shigeo Kitamura, Kota Kita, Mitsunori Matsushita</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">EyeControl: Towards Unconstrained Eye Tracking in Industrial Environments</span></div>
					<div><i>Florian Jungwirth, Michael Haslgrübler, Michaela Murauer, Benedikt Gollan, Pratheeban Elancheliyan, Alois Ferscha</i></div>
				</td>
			</tr>
			</tbody>
		</table>
	</div>

</section>

<section id="demos">

	<h2>Demos</h2>
	<div class="table-wrapper">
		<table>
			<tbody>

			<tr>
				<td>
					<div><span class="session-header">Using Affective Computing for Proxemic Interactions in Mixed-Reality</span></div>
					<div><i><u>Jasmine Roberts</u></i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">RealityAlert: Improving Users' Physical Safety in Immersive Virtual Environments</span></div>
					<div><i><u>Karim Huesmann</u>, Dimitar Valkov, Lars Linsen</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Using Whole-body Gestures for Interactive Slackline Training</span></div>
					<div><i><u>Florian Daiber</u>, Felix Kosmalla, Christian Murlowski, Antonio Krüger</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Spatially-Aware Tangibles Using Mouse Sensors</span></div>
					<div><i>Dennis Schüsselbauer, Andreas Schmid, <u>Raphael Wimmer</u>, Laurin Muth</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">MagicPAPER: An Integrated Shadow-Art Hardware Device Enabling Touch Interaction on Kraft paper</span></div>
					<div><i><u>Sirui Wang</u>, Jiayuan Wang, <u>Qin Wu</u></i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">CVR-Analyzer: A Tool for Analyzing Cinematic Virtual Reality Viewing Patterns</span></div>
					<div><i><u>Sylvia Rothe</u>, Tobias Höllerer, Heinrich Hussmann</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Cubic Keyboard for Virtual Reality</span></div>
					<div><i><u>Naoki Yanagihara</u>, Buntarou Shizuki</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Flip-Flop Sticker: Force-to-Motion Type 3DoF Input Device for Capacitive Touch Surface</span></div>
					<div><i><u>Kaori Ikematsu</u>, Masaaki Fukumoto, Itiro Siio</i></div>
				</td>
			</tr>
			<tr>
				<td>
					<div><span class="session-header">Air Maestros: A Multi-User Audiovisual Experience Using MR</span></div>
					<div><i><u>Ryu Nakagawa</u>, Ryo Komatsubara, Taku Ota, Hidefumi Ohmura</i></div>
				</td>
			</tr>

			<!--
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">Using Affective Computing for Proxemic Interactions in Mixed-Reality</span></div>
						<div><i><u>Jasmine Roberts</u></i></div>
						<div class="accordion-body">
							<br>
							This demo uses affective computing to explore paradigm of proxemics and privacy in mixed-reality. Use the Magic Leap HUD to determine the distance of personalized space required for human-human interaction.
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">RealityAlert: Improving Users' Physical Safety in Immersive Virtual Environments</span></div>
						<div><i><u>Karim Huesmann</u>, Dimitar Valkov, Lars Linsen</i></div>
						<div class="accordion-body">
							<br>
							<video width="100%" controls>
								<source src="videos/sui18b-sub1035-cam-i44.mp4" type="video/mp4">
								Your browser does not support HTML5 videos.
							</video>
							RealityAlert is a hardware device that we designed to alert immersive virtual environment (IVE) users for potential collisions with real-world (RW) objects. It uses distance sensors mounted on a head-mounted display (HMD) and vibro-tactile actuators inserted into the HMD's face cushion. We define a sensor-actuator mapping, which is minimally obtrusive in normal use, but efficiently alerting in risk situations.
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">Using Whole-body Gestures for Interactive Slackline Training</div>
						<div><i><u>Florian Daiber</u>, Felix Kosmalla, Christian Murlowski, Antonio Krüger</i></div>
						<div class="accordion-body">
							<br>
							Slackliner showcases how gestures can be applied to interactive sports training. SUI attendees can try out Slackliner to experience how spatial gestures can be used to interactively learn slacklining.
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">Spatially-Aware Tangibles Using Mouse Sensors</div>
						<div><i>Dennis Schüsselbauer, Andreas Schmid, <u>Raphael Wimmer</u>, Laurin Muth</i></div>
						<div class="accordion-body">
							<br>
							<video width="100%" controls>
								<source src="videos/sui18b-sub1033-cam-i44.mp4" type="video/mp4">
								Your browser does not support HTML5 videos.
							</video>
							Tangibles with embedded mouse sensors are able to determine their own absolute position and track their movement on a surface without external tracking infrastructure.
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">MagicPAPER: An Integrated Shadow-Art Hardware Device Enabling Touch Interaction on Kraft paper</div>
						<div><i><u>Sirui Wang</u>, Jiayuan Wang, <u>Qin Wu</u></i></div>
						<div class="accordion-body">
							<br>
							<video width="100%" controls>
								<source src="videos/sui18b-sub1029-cam-i44.mp4" type="video/mp4">
								Your browser does not support HTML5 videos.
							</video>
							In this study, we designed a shadow-art device for HCI called MagicPAPER. Compared with electronic screens and traditional painting, our system is more diverse and playable in terms of interaction.
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">CVR-Analyzer: A Tool for Analyzing Cinematic Virtual Reality Viewing Patterns</div>
						<div><i><u>Sylvia Rothe</u>, Tobias Höllerer, Heinrich Hussmann</i></div>
						<div class="accordion-body">
							<br>
							During our research on user attention in Cinematic Virtual Reality (CVR), we encountered many analytic demands and documented useful features. This motivated us to develop an analyzing tool: the CVR-Analyzer.
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">Cubic Keyboard for Virtual Reality</div>
						<div><i><u>Naoki Yanagihara</u>, Buntarou Shizuki</i></div>
						<div class="accordion-body">
							<br>
							<video width="100%" controls>
								<source src="videos/sui18b-sub1026-cam-i44.mp4" type="video/mp4">
								Your browser does not support HTML5 videos.
							</video>
							Our cubic keyboard for VR consists of 27 keys arranged in a 3×3×3 three-dimensional array, where all 26 alphabet characters are assigned to the 26 keys other than the center.
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">Flip-Flop Sticker: Force-to-Motion Type 3DoF Input Device for Capacitive Touch Surface</div>
						<div><i><u>Kaori Ikematsu</u>, Masaaki Fukumoto, Itiro Siio</i></div>
						<div class="accordion-body">
							<br>
							<video width="100%" controls>
								<source src="videos/sui18b-sub1022-cam-i44.mp4" type="video/mp4">
								Your browser does not support HTML5 videos.
							</video>
							We propose Flip-Flop Sticker, a novel force-to-motion type input device enabling 3DoF operations with intuitiveness and low fatigue.
							It works simply by attaching touch surfaces (e.g., trackpads or smartphones).
						</div>
					</div>
				</td>
			</tr>
			<tr>
				<td>
					<div class="accordion-wrapper">
						<div class="accordion-title">Air Maestros: A Multi-User Audiovisual Experience Using MR</div>
						<div><i><u>Ryu Nakagawa</u>, Ryo Komatsubara, Taku Ota, Hidefumi Ohmura</i></div>
						<div class="accordion-body">
							<br>
							The purpose of our demonstration system is to expand an ordinary music sequencer method into a three-dimensional (3D) space and a multi-user system. The users can be “Air Maestros.”
						</div>
					</div>
				</td>
			</tr>
			-->
			</tbody>
		</table>
	</div>

</section>


<!-- Section -->
<section>
	<div>
		<h2>Program Chairs<p style="font-size: 55%;"><a href="mailto:program@sui.acm.org">program@sui.acm.org</a></p></h2>
		<div class="posts">
			<article style = "margin-bottom:0;">
				<a href="http://imd.naist.jp/people/christiansandor/" class="image"><img src="images/christian_sandor.jpg" alt="" /></a>
				<h4 style = "margin-bottom:0;">Christian Sandor</h4><p style="text-align:left;"><i>Nara Institute of Science and Technology (NAIST), Japan</i></p>
			</article>
			<article style = "margin-bottom:0;">
				<a href="http://www.cs.uga.edu/directory/kyle-j-johnsen" class="image"><img src="images/kyle_johnsen.jpg" alt="" /></a>
				<h4 style = "margin-bottom:0;">Kyle Johnsen</h4><p style="text-align:left;"><i>University of Georgia, USA</i></p>
			</article>
			<article style = "margin-bottom:0;">
				<a href="http://imi.aau.dk/~sts/" class="image"><img src="images/stefania_serafin.jpg" alt="" /></a>
				<h4 style = "margin-bottom:0;">Stefania Serafin</h4><p style="text-align:left;"><i>Aalborg University, Denmark</i></p>
			</article>
		</div>
	</div>
</section>