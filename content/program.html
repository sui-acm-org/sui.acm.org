<section>
	<header class="main">
		<h1>Preliminary Program</h1>
	</header>

	<!-- dates -->
	<h2>Saturday, 13 October</h2>
	<div class="table-wrapper">
		<table>
			<tbody>
				<tr>
					<td style="width: 150px">8:30</td>
					<td>Registration opens</td>
				</tr>
				<tr>
					<td>9:00 - 9:15</td>
					<td>Opening</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>9:15 - 10:10</td>
					<td><span class="session-header">Session: Input and Output</span><br>
						<i>Robert J. Teather, Carleton University, Canada</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Pocket6: A 6DoF Controller Based On A Simple Smartphone App <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Teo Babic</u>, Harald Reiterer, Michael Haller</i></div>
							<div class="accordion-body">
								<br>
								We present Pocket6, a smartphone application for 6DoF user input. We present its implementation, performance study and demonstrate its use in diverse real-world scenarios.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Haptopus : Transferring the Touch Sense of the Hand to the Face Using Suction Mechanism Embedded in HMD <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Takayuki Kameoka</u>, Yuki Kon, Takuto Nakamura, Hiroyuki Kajimoto</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1059-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								We developed “Haptopus,” which embeds a tactile display in the HMD. Haptopus present high quality VR experience by transporting your fingertip sensation to your face using suction system.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>10:10 - 10:30</td>
					<td>Poster and Demo Fast Forward</td>
				</tr>
				<tr>
					<td>10:30 - 11:00</td>
					<td>Coffee break</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>11:00 - 12:30</td>
					<td><span class="session-header">Session: Sketching and Haptics</span><br>
						<i>Benjamin Weyers, RWTH Aachen University, Germany</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Performance Benefits of High-Fidelity Passive Haptic Feedback in Virtual Reality Training <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Anton Franzluebbers</u>, Kyle Johnsen</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1064-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								We describe a VR putting simulator uses a real golf club to move the virtual club. Our study finds performance and satisfaction benefits over ordinary controllers.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Physical Guides: An Analysis of 3D Sketching Performance on Physical Objects in Augmented Reality <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Philipp Wacker</u>, Adrian Wagner, Simon Voelker, Jan Borchers</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1053-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								How well can people trace specific lines on objects in AR? We compared tracing performance between physical and virtual objects as well as convex, concave, and visual guidance types.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Multiplanes: Assisted Freehand VR Sketching <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Mayra Donaji Barrera Machuca</u>, Paul Asente, Wolfgang Stuerzlinger, Jingwan Lu, Byungmoon Kim</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1034-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								Drawing in VR imposes high demands on users’ spatial cognition and motor skills. Multiplanes is a VR drawing system that let users sketch accurate 3D shapes in VR.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>12:30 - 13:30</td>
					<td>Lunch break (<i>on your own</i>)</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>13:30 - 15:00</td>
					<td><span class="session-header">Session: Presence and Collaboration</span><br>
						<i>Alexander Kulik, Bauhaus-Universität Weimar</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">IMRCE: A Unity Toolkit for Virtual Co-Presence <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Mohamad Hossein Salimian</u>, Stephen Brooks, Derek Reilly</i></div>
							<div class="accordion-body">
								<br>
								IMRCE is a lightweight, flexible, and robust Unity toolkit that allows designers and researchers to rapidly prototype mixed reality mixed presence (MR-MP) environments that connect physical spaces, virtual spaces and devices.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Over My Hand: Using a Personalized Hand in VR to Improve Object Size Estimation, Body Ownership, and Presence <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Sungchul Jung</u>, Gerd Bruder, Pamela J. Wisniewski, Christian Sandor, Dr. Charles E Hughes</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1018-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								In this paper, we investigate the impact of the personalized hand in VR in terms of virtual object size estimation, virtual bodyownership and spatial presence.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Injecting Nonverbal Mimicry with Hybrid Avatar-Agent Technologies: A naïve approach <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Daniel Roth</u>, David Mal, Christian Felix Purps, Peter Kullmann, Marc Erich Latoschik</i></div>
							<div class="accordion-body">
								<br>
								Future social interactions in VR will replicate user behavior with spatial and behavioral tracking. In our paper, we present an approach to modify these behavioral data by injecting nonverbal mimicry.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">A Look at the Effects of Handheld and Projected Augmented-reality on a Collaborative Task <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Eva Mackamul</u>, Augusto Esteves</i></div>
							<div class="accordion-body">
								<br>
								Our paper describes a study in which pairs of participants collaborate in handheld and project AR conditions. Their engagement, preference, task completion time, and number of actions is presented.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>15:00 - 15:30</td>
					<td>Coffee break and dedicated Demo session</td>
				</tr>
				<tr style="background-color: #FFF3CD">
					<td>15:30 - 17:00</td>
					<td><span class="session-header">Keynote by <a href="keynote-olwal">Alex Olwal</a>:</span><br>
						<strong>Fusing Interfaces with Matter, Humans and Machines</strong>
					</td>
				</tr>
			</tbody>
		</table>
		<table>
			<tbody>
				<tr style="background-color: #D1ECF1">
					<td style="width: 150px">20:00 - 23:00</td>
					<td>SUI social event @ Computer Games Museum<br>
						<i>Transfer to CGM takes about 15 min with U-Bahn</i>
					</td>
				</tr>
			</tbody>
		</table>
	</div>


	<h2>Sunday, 14 October</h2>
	<div class="table-wrapper">
		<table>
			<tbody>
				<tr>
					<td style="width: 150px">8:30</td>
					<td>Registration opens</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>9:00 - 10:30</td>
					<td><span class="session-header">Session: Space and Learning</span><br>
						<i>Frank Steinicke, University of Hamburg, Germany</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Improving Spatial Orientation in Immersive Environments <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Joseph T Kotlarek</u>, I-Chen Lin, Kwan-Liu Ma</i></div>
							<div class="accordion-body">
								<br>
								Take a look at the best ways to help users explore scientific visualizations. We evaluate Landmarks, Teleportation and WIMs for navigating VR environments with fusion particle data.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Effects of VE Transition Techniques on Presence, Illusion of Virtual Body Ownership, Efficiency, and Naturalness <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Sebastian Oberdörfer</u>, Martin Fischbach, Marc Erich Latoschik</i></div>
							<div class="accordion-body">
								<br>
								This paper presents three realizations of transition techniques targeting a travel between individual VEs. The metaphors are compared in regard to their effect on presence, IVBO, efficiency, and naturalism.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Getting There and Beyond: Incidental Learning of Spatial Knowledge with Turn-by-Turn Directions and Location Updates in Navigation Interfaces <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Sanorita Dey</u>, Karrie Karahalios, Wai-Tat Fu</i></div>
							<div class="accordion-body">
								<br>
								Simple design elements such as interactive location update and interactive orientation update can help people learn spatial knowledge incidentally while using a navigation interface. Let's find out how it works.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>10:30 - 11:00</td>
					<td>Coffee break and dedicated Poster session
					</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>11:00 - 12:30</td>
					<td><span class="session-header">Session: Selection and Travel</span><br>
						<i>Wolfgang Stuerzlinger, Simon Fraser University, Canada</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">Evaluating the Effects of Feedback Type on Older Adults’ Performance in Mid-Air Pointing and Target Selection <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Arthur Theil Cabreira</u>, Faustina Hwang</i></div>
							<div class="accordion-body">
								<br>
								In this work, we report the findings of a target acquisition experiment that investigated the effects of different 6 feedback conditions on how older adults performed point-and-select tasks in mid-air.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Evaluation of Cursor Offset on 3D Selection in VR <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i>Jialei Li, Isaac Cho, <u>Zachary Wartell</u></i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1096-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								Evaluation of four virtual cursor offset techniques on 3D object selection using Razer Hydra and Leap Motion in the Oculus Rift HMD.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Look to Go: An Empirical Evaluation of Eye-Based Travel in Virtual Reality <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i>YuanYuan Qian, <u>Robert J Teather</u></i></div>
							<div class="accordion-body">
								<br>
								We present two studies using the eye for locomotion in VR, using the eye tracker provided in the FOVE HMD.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>12:30 - 13:30</td>
					<td>Lunch (<i>on your own</i>)</td>
				</tr>
				<tr style="background-color: #FAEDED">
					<td>13:30 - 15:00</td>
					<td><span class="session-header">Session: Robotics and Wearables</span><br>
						<i>Dimitar Valkov, University of Münster, Germany</i><br>

						<div class="accordion-wrapper">
							<div class="accordion-title">RobotIST: Interactive Situated Tangible Robot Programming <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i><u>Yasaman S. Sefidgar</u>, Thomas Weng, Heather Harvey, Sarah Elliott, Maya Cakmak</i></div>
							<div class="accordion-body">
								<br>
								RobotIST enables robot programmers to program robotic manipulation of the physical environment in the physical space, leveraging tangible programming blocks as user input and providing projected feedback as system output.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Thumb-In-Motion: Evaluating Thumb to Ring Microgestures for Athletic Activity <span class="font-weight-normal">(<i>Long Paper</i>)</span></div>
							<div><i>Roger Boldu, Alexandru Dancu, <u>Denys J.C. Matthies</u>, Pablo Gallego Cascón, Shanaka Ransiri, Suranga Nanayakkara</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1089-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								In this paper, we evaluate a one-handed thumb-to-ring gesture interface to quickly access information without interfering with physical activity, such as running.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Development of a Wearable Haptic Device that Presents the Haptic  Sensation Corresponding to Three Fingers on the Forearm <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Taha Moriyama</u>, Takuto Nakamura, Hiroyuki Kajimoto</i></div>
							<div class="accordion-body">
								<br>
								In this paper, as an attempt for objects in virtual reality environment, we show a device that presents haptics sensation of the fingertip on the forearm, not on the fingertip.
							</div>
						</div>

						<div class="accordion-wrapper">
							<div class="accordion-title">Step Detection for Rollator Users with Smartwatches <span class="font-weight-normal">(<i>Short Paper</i>)</span></div>
							<div><i><u>Denys J.C. Matthies</u>, Marian Haescher, Suranga Nanayakkara, Gerald Bieber</i></div>
							<div class="accordion-body">
								<br>
								<video width="100%" controls>
									<source src="videos/sui18a-sub1023-cam-i41.mp4" type="video/mp4">
									Your browser does not support HTML5 videos.
								</video>
								We introduce an improved step-counting-algorithm for wrist-worn accelerometers. Our algorithm is capable of recognising steps when pulling/pushing objects, such as a rollator, which is a common assistive device for elderly people.
							</div>
						</div>
					</td>
				</tr>
				<tr>
					<td>15:00 - 15:30</td>
					<td>Coffee break</td>
				</tr>
				<tr style="background-color: #FFF3CD">
					<td>15:30 - 17:00</td>
					<td><span class="session-header">Closing Keynote by <a href="keynote-welch">Gregory Welch</a>:</span><br>
					<strong>The Rise of Allocentric Interfaces and the Collapse of the Virtuality Continuum</strong>
					</td>
				</tr>
				<tr>
					<td>17:00 - 17:30</td>
					<td>SUI 2018 Awards and Closing</td>
				</tr>
			</tbody>
		</table>
		<table>
			<tbody>
			<tr style="background-color: #D1ECF1">
					<td style="width: 150px">18:00 - 21:00</td>
					<td><a href="https://uist.acm.org/uist2018/program">UIST Reception and Demos at HPI</a><br>
						<i>(opened for SUI attendees)</i><br>
						<i>Transfer to HPI takes about 40 min with S-Bahn</i>
					</td>
				</tr>
			</tbody>
		</table>
	</div>

	<!--
	<h2>Monday, 15 October</h2>
	<div class="table-wrapper">
		<table>
			<tbody>
				<tr>
					<td style="width: 150px">10:00 - 11:00</td>
					<td>UIST Keynote by Jaime Teevan<br>
						<i>(opened for SUI attendees)</i>
					</td>
				</tr>
			</tbody>
		</table>
	</div>
	-->
</section>


<!-- Section -->
<section>
	<div>
		<h2>Program Chairs<p style="font-size: 55%;"><a href="mailto:program@sui.acm.org">program@sui.acm.org</a></p></h2>
		<div class="posts">
			<article style = "margin-bottom:0;">
				<a href="http://imd.naist.jp/people/christiansandor/" class="image"><img src="images/christian_sandor.jpg" alt="" /></a>
				<h4 style = "margin-bottom:0;">Christian Sandor</h4><p style="text-align:left;"><i>Nara Institute of Science and Technology (NAIST), Japan</i></p>
			</article>
			<article style = "margin-bottom:0;">
				<a href="http://www.cs.uga.edu/directory/kyle-j-johnsen" class="image"><img src="images/kyle_johnsen.jpg" alt="" /></a>
				<h4 style = "margin-bottom:0;">Kyle Johnsen</h4><p style="text-align:left;"><i>University of Georgia, USA</i></p>
			</article>
			<article style = "margin-bottom:0;">
				<a href="http://imi.aau.dk/~sts/" class="image"><img src="images/stefania_serafin.jpg" alt="" /></a>
				<h4 style = "margin-bottom:0;">Stefania Serafin</h4><p style="text-align:left;"><i>Aalborg University, Denmark</i></p>
			</article>
		</div>
	</div>
</section>